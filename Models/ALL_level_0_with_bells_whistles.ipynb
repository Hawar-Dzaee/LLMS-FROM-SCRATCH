{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch import nn \n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import tiktoken \n",
    "import matplotlib.pyplot as plt \n",
    "import plotly.graph_objects as go \n",
    "\n",
    "import math "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "  device = 'cuda'\n",
    "# elif torch.backends.mps.is_available():\n",
    "#   device = 'mps'\n",
    "else :\n",
    "  device = 'cpu'\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 :  Fetch The Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 20 characters: I HAD always thought\n",
      "Number of Characters: 20479\n"
     ]
    }
   ],
   "source": [
    "with open('the-verdict.txt','r',encoding='utf-8') as f:\n",
    "  raw_text = f.read()\n",
    "\n",
    "print(f'First 20 characters: {raw_text[:20]}')\n",
    "print(f'Number of Characters: {len(raw_text)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 : Dataset Preparation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data(Dataset):\n",
    "  def __init__(self,raw_text,tokenizer,context_window,stride):\n",
    "    self.token_id = tokenizer.encode(raw_text)\n",
    "    self.X = []\n",
    "    self.y = []\n",
    "\n",
    "    for i in range(0,len(self.token_id)-context_window,stride):\n",
    "      input_chunks = self.token_id[i:i+context_window]\n",
    "      output_chunks = self.token_id[(i)+1:(i+context_window) +1]\n",
    "      self.X.append(torch.tensor(input_chunks))\n",
    "      self.y.append(torch.tensor(output_chunks))\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.X)\n",
    "\n",
    "  def __getitem__(self,idx):\n",
    "    return self.X[idx],self.y[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split \n",
    "\n",
    "Notice we split the corpus to train/val before creating the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18431\n"
     ]
    }
   ],
   "source": [
    "ratio = 0.90\n",
    "split_index = int(len(raw_text)* ratio)\n",
    "print(split_index)\n",
    "\n",
    "train_text = raw_text[:split_index]\n",
    "val_text = raw_text[split_index:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens 4612\n",
      "Number of tokens 534\n"
     ]
    }
   ],
   "source": [
    "train_ds = Data(train_text,tiktoken.get_encoding('gpt2'),context_window=256,stride=256)   # notice stride == context_window (in that case there wont be any overlap)\n",
    "val_ds   = Data(val_text,tiktoken.get_encoding('gpt2'),context_window=256,stride=256)     # *Same as above \n",
    "\n",
    "print(f'Number of tokens {len(train_ds.token_id)}')\n",
    "print(f'Number of tokens {len(val_ds.token_id)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataLoader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds,batch_size=2,shuffle=False,drop_last=True, num_workers=0)\n",
    "val_dl   = DataLoader(val_ds,  batch_size=2,shuffle=False,drop_last=False,num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dl))\n",
    "print(len(val_dl))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "X : torch.Size([2, 256])\n",
      "y : torch.Size([2, 256])\n",
      "------------------------------\n",
      "2\n",
      "X : torch.Size([2, 256])\n",
      "y : torch.Size([2, 256])\n",
      "------------------------------\n",
      "3\n",
      "X : torch.Size([2, 256])\n",
      "y : torch.Size([2, 256])\n",
      "------------------------------\n",
      "4\n",
      "X : torch.Size([2, 256])\n",
      "y : torch.Size([2, 256])\n",
      "------------------------------\n",
      "5\n",
      "X : torch.Size([2, 256])\n",
      "y : torch.Size([2, 256])\n",
      "------------------------------\n",
      "6\n",
      "X : torch.Size([2, 256])\n",
      "y : torch.Size([2, 256])\n",
      "------------------------------\n",
      "7\n",
      "X : torch.Size([2, 256])\n",
      "y : torch.Size([2, 256])\n",
      "------------------------------\n",
      "8\n",
      "X : torch.Size([2, 256])\n",
      "y : torch.Size([2, 256])\n",
      "------------------------------\n",
      "9\n",
      "X : torch.Size([2, 256])\n",
      "y : torch.Size([2, 256])\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i,(x,y) in enumerate(train_dl):\n",
    "  print(i+1)\n",
    "  print(f'X : {x.shape}')\n",
    "  print(f'y : {y.shape}')\n",
    "  print('---'*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "X : torch.Size([2, 256])\n",
      "y : torch.Size([2, 256])\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i,(x,y) in enumerate(val_dl):\n",
    "  print(i+1)\n",
    "  print(f'X : {x.shape}')\n",
    "  print(f'y : {y.shape}')\n",
    "  print('---'*10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversions \n",
    "\n",
    "These conversion functions allow us to convert text to token_ids,and vice versa easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_token_ids(text,tokenizer=tiktoken.get_encoding('gpt2')):\n",
    "  token_ids = tokenizer.encode(text,allowed_special={'<|endoftext|>'})              # python list.\n",
    "  token_ids_in_tensors = torch.tensor(token_ids).unsqueeze(0)                       # tensor,with batch dimesion.\n",
    "  return token_ids_in_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[15496,   428,   318,   387,  5767,   220, 50256]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_to_token_ids('Hello this is hawar <|endoftext|>')    # Note : the last token_id is 50256, (50257) is the vocab size by the author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_ids_to_text(token_ids_in_tensors,tokenizer=tiktoken.get_encoding('gpt2')):\n",
    "  token_ids = token_ids_in_tensors.squeeze(0).tolist()    # Note: It can only handle batch_size = 1\n",
    "  text = tokenizer.decode(token_ids)\n",
    "  return text "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3 : Multi-Head-Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "class MultiHeadAttention(nn.Module):\n",
    "  def __init__(self,d_in,d_out,\n",
    "               context_window,    # The context window is needed here to create the mask.\n",
    "               num_heads,\n",
    "               dp_attn,qkv_bias=False):\n",
    "    \n",
    "    super().__init__()\n",
    "\n",
    "    assert d_out%num_heads == 0, 'd_out must be divisble by num_heads'\n",
    "    self.d_out = d_out\n",
    "    self.num_heads = num_heads\n",
    "    self.head_dim = self.d_out //self.num_heads # dimension of each head\n",
    "\n",
    "    self.W_q = nn.Linear(d_in,d_out,bias=qkv_bias)\n",
    "    self.W_k = nn.Linear(d_in,d_out,bias=qkv_bias)\n",
    "    self.W_v = nn.Linear(d_in,d_out,bias=qkv_bias)\n",
    "\n",
    "    self.register_buffer('mask',torch.triu(torch.ones(context_window,context_window),diagonal=1))\n",
    "    # why shape (context_window,context_window) ? beacause we'll use it on Q@KT which will have shape of (b,self.num_heads,context_window,context_window)\n",
    "    # But since we might have different num_tokens(i.e num_tokens is not context_window for every case) we will slice it to [:num_tokens][:num_tokens]\n",
    "    # This slicing wont be necessary if num_tokens == context window\n",
    "    \n",
    "    self.dropout = nn.Dropout(dp_attn)\n",
    "    self.out_proj = nn.Linear(d_out,d_out)\n",
    "\n",
    "\n",
    "  def forward(self,x):\n",
    "    b,num_tokens,d_in = x.shape\n",
    "\n",
    "    Q = self.W_q(x)\n",
    "    K = self.W_k(x)\n",
    "    V = self.W_v(x)\n",
    "\n",
    "    # split \n",
    "    Q = Q.view(b,num_tokens,self.num_heads,self.head_dim).transpose(1,2)  # result : (b,self.num_heads,num_tokens,self.head_dim)\n",
    "    K = K.view(b,num_tokens,self.num_heads,self.head_dim).transpose(1,2)\n",
    "    V = V.view(b,num_tokens,self.num_heads,self.head_dim).transpose(1,2)\n",
    "\n",
    "    # \n",
    "    attn_score = Q @ K.transpose(2,3) # result : (b,self.num_head,num_tokens,num_tokens)\n",
    "    attn_score.masked_fill_(self.mask.bool()[:num_tokens,:num_tokens],-torch.inf)\n",
    "    attn_weight = torch.softmax(attn_score/(K.shape[-1]**0.5),dim=-1)\n",
    "    attn_weight = self.dropout(attn_weight)\n",
    "\n",
    "    context_vec = attn_weight @ V # result : (b,self.num_head,num_toknes,self.head_dim)\n",
    "    context_vec = context_vec.transpose(1,2).contiguous().view(b,num_tokens,self.d_out)\n",
    "    context_vec = self.out_proj(context_vec)\n",
    "\n",
    "    return context_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4 : Transformers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "  def __init__(self,cfg):\n",
    "    super().__init__()\n",
    "\n",
    "    self.norm1 = nn.LayerNorm(cfg['d_out'])\n",
    "    self.attn = MultiHeadAttention(cfg['d_in'],cfg['d_out'],cfg['context_window'],cfg['num_heads'],cfg['dp_attn'],cfg['qkv_bias'])\n",
    "    self.dp_after_attn = nn.Dropout(cfg['dp_after_attn'])\n",
    "\n",
    "    self.norm2 = nn.LayerNorm(cfg['d_out'])\n",
    "    self.fc = nn.Sequential(nn.Linear(cfg['d_out'],4*cfg['d_out']),\n",
    "                            nn.GELU(),\n",
    "                            nn.Linear(4*cfg['d_out'],cfg['d_out']))\n",
    "    self.dp_after_fc = nn.Dropout(cfg['dp_after_fc'])\n",
    "\n",
    "  def forward(self,x):\n",
    "    shortcut = x  \n",
    "    x = self.norm1(x)\n",
    "    x = self.attn(x)\n",
    "    x = self.dp_after_attn(x)\n",
    "    x = x + shortcut\n",
    "\n",
    "    shortcut = x\n",
    "    x = self.norm2(x)\n",
    "    x = self.fc(x)\n",
    "    x = self.dp_after_fc(x)\n",
    "    x = x + shortcut\n",
    "\n",
    "    return x \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model's Configuration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# change the following with a bigger model.\n",
    "\n",
    "GPT_CONFIG_124M = {    #TransformerBlock Level\n",
    "          'd_in':768,\n",
    "           'd_out':768,\n",
    "           'context_window':256,  # You can not have num_tokens greater than this number \n",
    "           'num_heads':12,\n",
    "           \n",
    "           'dp_attn':0.1,\n",
    "           'dp_after_attn':0.1,\n",
    "           'dp_after_fc':0.1,\n",
    "\n",
    "           'qkv_bias':False,\n",
    "           \n",
    "            # GPTModel Level\n",
    "           'dp_before_attn':0.1,\n",
    "           'vocab_size':50256+1,\n",
    "           'num_layers':12}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 5 : GPT Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTModel(nn.Module):\n",
    "  def __init__(self,cfg):\n",
    "    super().__init__()\n",
    "    self.tok_emb = nn.Embedding(cfg['vocab_size'],cfg['d_in'])\n",
    "    self.pos_emb = nn.Embedding(cfg['context_window'],cfg['d_in'])\n",
    "    self.dp_before_trans = nn.Dropout(cfg['dp_before_attn'])\n",
    "    self.transformer_blocks = nn.Sequential(*[TransformerBlock(cfg) for _ in range(cfg['num_layers'])])\n",
    "    self.final_norm = nn.LayerNorm(cfg['d_out'])\n",
    "    self.head_out = nn.Linear(cfg['d_out'],cfg['vocab_size'])\n",
    "\n",
    "  def forward(self,x):\n",
    "    b,num_tokens = x.shape\n",
    "\n",
    "    tok_em = self.tok_emb(x)\n",
    "    pos_em = self.pos_emb(torch.arange(num_tokens,device=device))   # this is where it can handle dynamic sequence lengths (as long as it's lower than context window)\n",
    "    x = tok_em + pos_em\n",
    "\n",
    "    x = self.dp_before_trans(x)\n",
    "    x = self.transformer_blocks(x)\n",
    "    x = self.final_norm(x)\n",
    "    logits = self.head_out(x)\n",
    "\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPTModel(GPT_CONFIG_124M).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-1.1501e-01, -4.0099e-01, -7.0368e-02,  ...,  5.5857e-02,\n",
      "          -4.8014e-01,  3.7116e-01],\n",
      "         [ 6.1407e-02, -1.4992e-01,  1.0680e+00,  ...,  4.3743e-01,\n",
      "          -7.0324e-01,  4.2321e-01],\n",
      "         [ 4.6695e-01,  2.3328e-01, -3.4185e-02,  ...,  6.2094e-01,\n",
      "          -6.9301e-01,  3.5567e-01],\n",
      "         ...,\n",
      "         [ 8.3024e-02, -2.7019e-01,  5.7516e-02,  ...,  4.7997e-01,\n",
      "           5.8081e-02,  6.7800e-01],\n",
      "         [ 5.8204e-01,  6.1453e-01,  6.5674e-01,  ..., -2.5922e-01,\n",
      "          -1.9805e-01,  5.0750e-01],\n",
      "         [-3.4647e-01,  6.2501e-01,  6.0778e-01,  ...,  5.1414e-01,\n",
      "           3.9566e-01, -8.4009e-01]],\n",
      "\n",
      "        [[-5.2159e-01, -3.2698e-01, -3.3057e-01,  ...,  1.9990e-01,\n",
      "           6.9118e-01,  3.8865e-01],\n",
      "         [ 2.7139e-01, -8.9852e-02,  3.9952e-01,  ...,  5.9899e-01,\n",
      "          -3.8721e-01, -4.0687e-01],\n",
      "         [ 5.2349e-01, -7.6593e-02, -6.5530e-01,  ..., -3.0248e-01,\n",
      "          -1.1583e+00, -5.8816e-01],\n",
      "         ...,\n",
      "         [ 2.2410e-01, -1.3619e-01, -1.0972e+00,  ..., -5.8028e-01,\n",
      "           1.2618e+00,  4.0446e-01],\n",
      "         [ 6.1640e-01,  2.0796e+00,  8.5094e-01,  ...,  9.0663e-02,\n",
      "           2.7238e-01,  9.6674e-01],\n",
      "         [-1.3609e-01,  8.1424e-01, -1.3464e-03,  ...,  2.5297e-01,\n",
      "           5.9572e-01, -9.1828e-01]]])\n",
      "torch.Size([2, 256, 50257])\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "  print(model(torch.randint(0,50257,(2,256)).to(device)))        # torch.randint(0,vocab_size,(batch_size,num_tokens))     PS: num_tokens must be <= context_window\n",
    "  print(model(torch.randint(0,50257,(2,256)).to(device)).shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 6 : Next token  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we dont slice the mask, it will throw an error here, why?  beacuase the input num_tokens != context_window \n",
    "\n",
    "def generate_simple_text(starting_text,\n",
    "                         context_window,    # this can be anything between [1,context_window]\n",
    "                         num_tokens_generated = 20,temperature=1,k=None):  \n",
    "  \n",
    "    starting_tokens = text_to_token_ids(starting_text).to(device)       # this will have the shape (B=1,number of tokens after converting text to token ids)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for _ in range(num_tokens_generated):\n",
    "            starting_tokens = starting_tokens[:,-context_window:]    # how far back to pay attention \n",
    "            logits = model(starting_tokens)[:,-1,:]                  # we only want the last vector\n",
    "\n",
    "            # new\n",
    "            if k is not None:\n",
    "              top_logits, _ = torch.topk(logits,k)                                      # find top 3. \n",
    "              new_logits = torch.where(logits<top_logits[:,-1],-torch.inf,logits)       # keep top 3, make other -inf.\n",
    "              probs = torch.softmax(new_logits/temperature,dim=-1)                                  # probability of top 3 , the rest will be zero.\n",
    "              token_predicted = torch.multinomial(probs,num_samples = 1)                # pick one (according to their probability) from top 3.\n",
    "            # End\n",
    "            else : \n",
    "                token_predicted = torch.argmax(logits,dim=-1,keepdim=True)\n",
    "            \n",
    "            starting_tokens = torch.cat([starting_tokens,token_predicted],dim=-1)\n",
    "            \n",
    "        print(token_ids_to_text(starting_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Everty effort moves youreligiouszzo distortionscommerceventionalplings intellectual lore Mud }}annah Specialiologist Examplesector461 Exhibitvention Yugoslav aggrav\n"
     ]
    }
   ],
   "source": [
    "generate_simple_text(starting_text='Everty effort moves you',context_window=GPT_CONFIG_124M['context_window'],temperature=0.2,k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 7 : Training "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning rate warmup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_steps  : 135\n",
      "warmup_steps : 27\n",
      "Learning Rate Increment: 0.00036666666666666667\n",
      "work_steps : 108\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 15\n",
    "\n",
    "initial_lr = 0.0001           # we will start with this \n",
    "peak_lr = 0.01                # by the end of the warmup we will have this \n",
    "min_lr = 0.1 * initial_lr\n",
    "\n",
    "\n",
    "# warmup_steps = 20     \n",
    "\n",
    "global_step = -1 \n",
    "\n",
    "total_steps = len(train_dl)*n_epochs      # 9 * 15 \n",
    "print(f'total_steps  : {total_steps}')\n",
    "\n",
    "warmup_steps = int(0.2 * total_steps)     # The warmup is usually between 0.1% - 20.0% of total steps(in this case we're using 20.0%)\n",
    "print(f'warmup_steps : {warmup_steps}')\n",
    "\n",
    "\n",
    "lr_increment = (peak_lr - initial_lr)/ warmup_steps\n",
    "print(f'Learning Rate Increment: {lr_increment}') # we add this to initial_lr for warmup_steps (in this case 27 times)\n",
    "\n",
    "work_steps = total_steps - warmup_steps\n",
    "print(f'work_steps : {work_steps}')   # This is from step 27 till 135"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(),weight_decay =0.1)   # weight decay is L2 norm regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 00   Training Loss : 7.55       Validation Loss : 7.646\n",
      "Everty effort moves you .,, . I I . I, . I .,, .\n",
      "\n",
      " I I I\n",
      "=============================================================================================================================\n",
      "Epoch : 01   Training Loss : 7.149      Validation Loss : 8.359\n",
      "Everty effort moves you of the of the the the of the------ the of the-- the of of the the\n",
      "=============================================================================================================================\n",
      "Epoch : 02   Training Loss : 7.328      Validation Loss : 8.996\n",
      "Everty effort moves you\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " I. I--..\n",
      "\n",
      ". I I\n",
      "=============================================================================================================================\n",
      "Epoch : 03   Training Loss : 7.069      Validation Loss : 8.211\n",
      "Everty effort moves you it it to and to and and to and and it it and and and and it and and to\n",
      "=============================================================================================================================\n",
      "Epoch : 04   Training Loss : 6.597      Validation Loss : 7.681\n",
      "Everty effort moves you the\n",
      "\n",
      " the\n",
      " the\n",
      " of of\n",
      " the\n",
      " the to the of the\n",
      " the the\n",
      "=============================================================================================================================\n",
      "Epoch : 05   Training Loss : 6.2        Validation Loss : 7.274\n",
      "Everty effort moves you I the I,.,,.,.,.,,,,. I,.\n",
      "=============================================================================================================================\n",
      "Epoch : 06   Training Loss : 6.028      Validation Loss : 7.097\n",
      "Everty effort moves you to. to.,,.... to. to,,,. to the the\n",
      "=============================================================================================================================\n",
      "Epoch : 07   Training Loss : 5.95       Validation Loss : 7.032\n",
      "Everty effort moves you I,\n",
      ",,\n",
      ",\n",
      ",.\n",
      ",\n",
      " the,.,,,,\n",
      "=============================================================================================================================\n",
      "Epoch : 08   Training Loss : 5.902      Validation Loss : 7.004\n",
      "Everty effort moves you..\n",
      "\n",
      "\n",
      "\n",
      ",,\n",
      ",,,\n",
      " the.,,...\n",
      "=============================================================================================================================\n",
      "Epoch : 09   Training Loss : 5.878      Validation Loss : 7.012\n",
      "Everty effort moves you,\n",
      " the,,\n",
      ",\n",
      " the,..,\n",
      "\n",
      "\n",
      ",,.\n",
      "\n",
      "=============================================================================================================================\n",
      "Epoch : 10   Training Loss : 5.84       Validation Loss : 7.022\n",
      "Everty effort moves you,\n",
      "\n",
      "\n",
      "\n",
      ".,., the..,.,,.\n",
      ",\n",
      "\n",
      "=============================================================================================================================\n",
      "Epoch : 11   Training Loss : 5.815      Validation Loss : 7.028\n",
      "Everty effort moves you,,, I, I,,.\n",
      ", the.,\n",
      ",,. I,\n",
      "=============================================================================================================================\n",
      "Epoch : 12   Training Loss : 5.799      Validation Loss : 7.034\n",
      "Everty effort moves you I, I the\n",
      " the. I\n",
      " the,,\n",
      ". I\n",
      " the\n",
      " the the\n",
      "=============================================================================================================================\n",
      "Epoch : 13   Training Loss : 5.79       Validation Loss : 7.036\n",
      "Everty effort moves you,\n",
      " the, I the\n",
      "\n",
      ",,,,.\n",
      " the,,\n",
      " the,\n",
      "=============================================================================================================================\n",
      "Epoch : 14   Training Loss : 5.783      Validation Loss : 7.036\n",
      "Everty effort moves you\n",
      " I,.,, the\n",
      "\n",
      "\n",
      " the the,\n",
      "\n",
      ",,.\n",
      "\n",
      "\n",
      "=============================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "TRAIN_LOSS,VAL_LOSS = [],[]\n",
    "tracks_lr = []\n",
    "\n",
    "for epoch in range(n_epochs) :\n",
    "  print(f'Epoch : {epoch:02d}',end='   ')                                                    # first print()\n",
    "  train_loss,val_loss = [],[]\n",
    "\n",
    "  # TRAINING \n",
    "  model.train()\n",
    "  for x,y in train_dl:\n",
    "    x,y = x.to(device),y.to(device)\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # New ------------------------------------------------------------------\n",
    "\n",
    "    global_step += 1 \n",
    "    #  Learning rate warmup \n",
    "    if global_step < warmup_steps :\n",
    "      lr = initial_lr + (global_step * lr_increment)\n",
    "    # cosine decay \n",
    "    else : \n",
    "      progress = ((global_step - warmup_steps) / (work_steps))                  \n",
    "      lr = min_lr + (peak_lr - min_lr) * 0.5 * (1 + math.cos(math.pi * progress))\n",
    "\n",
    "\n",
    "    for param_groups in optimizer.param_groups:   # pytorch new.\n",
    "      param_groups['lr'] = lr \n",
    "\n",
    "    tracks_lr.append(optimizer.param_groups[0]['lr'])\n",
    "    # print(f'{global_step} , {optimizer.param_groups[0]['lr']}')     \n",
    "\n",
    "    # gradient clipping \n",
    "    if global_step > warmup_steps:    # meaning if we are in work_steps(i.e 27-135)\n",
    "      torch.nn.utils.clip_grad_norm_(model.parameters(),max_norm=1.0)\n",
    "\n",
    "    # -----------------------------------------------------------------------\n",
    "    y_hat = model(x)\n",
    "    loss = loss_fn(y_hat.flatten(0,1),y.flatten())    # y_hat result : (512,50257),    y result : (512) \n",
    "    train_loss.append(loss.item())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "  mean_epoch_train_loss = round(torch.mean(torch.tensor(train_loss)).item(),3)\n",
    "  print(f'Training Loss : {mean_epoch_train_loss:<10}',end=' ')                                 # second print()         \n",
    "  TRAIN_LOSS.append(mean_epoch_train_loss)\n",
    "\n",
    "  # VALIDATION \n",
    "  model.eval()\n",
    "  with torch.no_grad():\n",
    "    for x,y in val_dl:\n",
    "      x,y = x.to(device),y.to(device)\n",
    "      y_hat = model(x)\n",
    "      loss = loss_fn(y_hat.flatten(0,1),y.flatten())\n",
    "      val_loss.append(loss.item())\n",
    "\n",
    "    mean_epoch_val_loss = round(torch.tensor(val_loss).mean().item(),3)                         # Third print()\n",
    "    print(f'Validation Loss : {mean_epoch_val_loss}')\n",
    "    VAL_LOSS.append(mean_epoch_val_loss)\n",
    "\n",
    "  # Generate text \n",
    "  generate_simple_text(starting_text='Everty effort moves you',context_window=GPT_CONFIG_124M['context_window'],num_tokens_generated = 20,k=3)\n",
    "\n",
    "  print('====='*25)\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 8.0 : Train/Val Loss Plot  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "line": {
          "color": "red"
         },
         "mode": "lines",
         "name": "Training Loss",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14
         ],
         "y": [
          7.55,
          7.149,
          7.328,
          7.069,
          6.597,
          6.2,
          6.028,
          5.95,
          5.902,
          5.878,
          5.84,
          5.815,
          5.799,
          5.79,
          5.783
         ]
        },
        {
         "line": {
          "color": "yellow"
         },
         "mode": "lines",
         "name": "Validation Loss",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14
         ],
         "y": [
          7.646,
          8.359,
          8.996,
          8.211,
          7.681,
          7.274,
          7.097,
          7.032,
          7.004,
          7.012,
          7.022,
          7.028,
          7.034,
          7.036,
          7.036
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_curve = go.Scatter(\n",
    "  x = torch.arange(n_epochs),\n",
    "  y = TRAIN_LOSS,\n",
    "  mode = 'lines',\n",
    "  line = dict(color='red'),\n",
    "  name = 'Training Loss'\n",
    ")\n",
    "\n",
    "valid_curve = go.Scatter(\n",
    "  x = torch.arange(n_epochs),\n",
    "  y = VAL_LOSS,\n",
    "  mode = 'lines',\n",
    "  line = dict(color='yellow'),\n",
    "  name = 'Validation Loss'\n",
    ")\n",
    "\n",
    "figure = go.Figure(data=[training_curve,valid_curve])\n",
    "figure.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 8.1 : Learning Rate Plot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "line": {
          "color": "blue"
         },
         "mode": "lines",
         "name": "Learning Rate",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134
         ],
         "y": [
          0.0026666666666666666,
          0.003033333333333333,
          0.0034,
          0.0037666666666666664,
          0.0041333333333333335,
          0.0045000000000000005,
          0.004866666666666667,
          0.005233333333333334,
          0.0056,
          0.005966666666666667,
          0.006333333333333334,
          0.0067,
          0.007066666666666667,
          0.0074333333333333335,
          0.0078000000000000005,
          0.008166666666666666,
          0.008533333333333332,
          0.0089,
          0.009266666666666666,
          0.009633333333333332,
          0.01,
          0.009997886865660593,
          0.009991549250564986,
          0.00998099251696827,
          0.009966225596921006,
          0.009947260984711817,
          0.00992411472629598,
          0.00989680640571893,
          0.00986535912854622,
          0.009829799502313896,
          0.009790157614015867,
          0.009746467004647305,
          0.009698764640825613,
          0.009647090883512977,
          0.00959148945386697,
          0.009532007396248068,
          0.009468695038415444,
          0.009401605948944654,
          0.009330796891903272,
          0.009256327778822813,
          0.009178261618007617,
          0.009096664461223515,
          0.009011605347811443,
          0.008923156246273281,
          0.008831391993379295,
          0.008736390230848776,
          0.008638231339657378,
          0.008536998372026804,
          0.008432776981154326,
          0.008325655348741618,
          0.008215724110384263,
          0.00810307627888496,
          0.007987807165555418,
          0.007870014299573475,
          0.007749797345463676,
          0.0076272580187711275,
          0.0075025000000000005,
          0.007375628846889464,
          0.007246751905101309,
          0.007115978217394794,
          0.006983418431365588,
          0.006849184705826859,
          0.006713390615911716,
          0.006576151056977311,
          0.006437582147391896,
          0.0062978011302870915,
          0.006156926274358488,
          0.00601507677379853,
          0.005872372647446318,
          0.0057289346372396965,
          0.0055848841060555255,
          0.005440342935024553,
          0.005295433420407826,
          0.005150278170121841,
          0.005005,
          0.004859721829878158,
          0.004714566579592174,
          0.004569657064975447,
          0.004425115893944474,
          0.004281065362760303,
          0.004137627352553683,
          0.003994923226201472,
          0.0038530737256415116,
          0.0037121988697129088,
          0.0035724178526081057,
          0.003433848943022691,
          0.0032966093840882853,
          0.003160815294173142,
          0.0030265815686344117,
          0.0028940217826052073,
          0.0027632480948986916,
          0.0026343711531105363,
          0.0025075000000000015,
          0.0023827419812288727,
          0.0022602026545363242,
          0.0021399857004265263,
          0.002022192834444584,
          0.0019069237211150412,
          0.001794275889615736,
          0.0016843446512583803,
          0.0015772230188456763,
          0.0014730016279731956,
          0.0013717686603426217,
          0.0012736097691512266,
          0.0011786080066207055,
          0.0010868437537267194,
          0.0009983946521885567,
          0.0009133355387764855,
          0.0008317383819923834,
          0.0007536722211771864,
          0.0006792031080967287,
          0.0006083940510553457,
          0.0005413049615845563,
          0.00047799260375193365,
          0.000418510546133032,
          0.00036290911648702144,
          0.000311235359174388,
          0.00026353299535269574,
          0.00021984238598413296,
          0.00018020049768610434,
          0.0001446408714537801,
          0.00011319359428107037,
          0.00008588527370402094,
          0.00006273901528818237,
          0.0000437744030789946,
          0.000029007483031731003,
          0.000018450749435015464,
          0.000012113134339408007,
          0.00001,
          0.000012113134339408007,
          0.000018450749435015464,
          0.000029007483031731003,
          0.0000437744030789946,
          0.00006273901528818237,
          0.00008588527370402094
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr_plot = go.Scatter(\n",
    "  x = list(range(len(tracks_lr))),\n",
    "  y = tracks_lr,\n",
    "  mode = 'lines',\n",
    "  line = dict(color='blue'),\n",
    "  name= \"Learning Rate\"\n",
    ")\n",
    "\n",
    "figure = go.Figure(data=lr_plot)\n",
    "figure.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and Saving model weights in Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(\n",
    "  {'model_state_dict':model.state_dict(),\n",
    "   'optimizer_state_dict':optimizer.state_dict()},\n",
    "   'model_and_optimizers.pth'\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qq/xcj55x9n0hs0jx2pcwy46_mc0000gn/T/ipykernel_74572/680644273.py:1: FutureWarning:\n",
      "\n",
      "You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "checkpoint = torch.load('model_and_optimizers.pth',map_location=device)\n",
    "\n",
    "\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(),lr=0.0004,weight_decay =0.1)\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatting",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
