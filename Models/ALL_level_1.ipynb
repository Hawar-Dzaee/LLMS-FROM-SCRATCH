{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following notebooks is exactly as `ALL_level_0`, except for using from scratch class `MultiheadAttention` we use pytorch's `nn.MultiheadAttention`\n",
    "which decreases the amount of code we write immensly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch import nn \n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import tiktoken \n",
    "import matplotlib.pyplot as plt \n",
    "import plotly.graph_objects as go "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "  device = 'cuda'\n",
    "# elif torch.backends.mps.is_available():\n",
    "#   device = 'mps'\n",
    "else :\n",
    "  device = 'cpu'\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model's Configuration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfg = {    #TransformerBlock Level\n",
    "#           'd_in':12,\n",
    "#            'd_out':12,\n",
    "#            'context_window':256,  # You can not have num_tokens greater than this number \n",
    "#            'num_heads':4,\n",
    "\n",
    "#            'dp_attn':0.0,\n",
    "#            'dp_after_trans':0.0,\n",
    "#            'dp_after_fc':0.0,\n",
    "\n",
    "#            'qkv_bias':False,\n",
    "           \n",
    "#             # GPTModel Level\n",
    "#            'dp_before_trans':0.0,\n",
    "#            'vocab_size':50256+1,\n",
    "#            'num_layers':4}\n",
    "\n",
    "#-----------------------------------------------------\n",
    "\n",
    "GPT_CONFIG_124M = {    #TransformerBlock Level\n",
    "          'd_in':768,\n",
    "           'd_out':768,\n",
    "           'context_window':256,  # You can not have num_tokens greater than this number \n",
    "           'num_heads':12,\n",
    "\n",
    "           'dp_attn':0.1,\n",
    "           'dp_after_attn':0.1,\n",
    "           'dp_after_fc':0.1,\n",
    "\n",
    "           'qkv_bias':False,\n",
    "           \n",
    "            # GPTModel Level\n",
    "           'dp_before_trans':0.1,\n",
    "           'vocab_size':50256+1,\n",
    "           'num_layers':12}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 :  Fetch The Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 20 characters: I HAD always thought\n",
      "Number of Characters: 20479\n"
     ]
    }
   ],
   "source": [
    "with open('the-verdict.txt','r',encoding='utf-8') as f:\n",
    "  raw_text = f.read()\n",
    "\n",
    "print(f'First 20 characters: {raw_text[:20]}')\n",
    "print(f'Number of Characters: {len(raw_text)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 : Dataset Preparation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data(Dataset):\n",
    "  def __init__(self,raw_text,tokenizer,context_window,stride):\n",
    "    self.token_id = tokenizer.encode(raw_text)\n",
    "    self.X = []\n",
    "    self.y = []\n",
    "\n",
    "    for i in range(0,len(self.token_id)-context_window,stride):\n",
    "      input_chunks = self.token_id[i:i+context_window]\n",
    "      output_chunks = self.token_id[(i)+1:(i+context_window) +1]\n",
    "      self.X.append(torch.tensor(input_chunks))\n",
    "      self.y.append(torch.tensor(output_chunks))\n",
    "\n",
    "  def __len__(self):return len(self.X)\n",
    "\n",
    "  def __getitem__(self,idx):return self.X[idx],self.y[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split \n",
    "\n",
    "Notice we split the corpus to train/val before creating the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio = 0.9\n",
    "split_index = int(len(raw_text)*0.9)\n",
    "\n",
    "train_text = raw_text[:split_index]\n",
    "val_text = raw_text[split_index:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens 4612\n",
      "Number of tokens 534\n"
     ]
    }
   ],
   "source": [
    "train_ds = Data(train_text,tiktoken.get_encoding('gpt2'),context_window=256,stride=128)\n",
    "val_ds   = Data(val_text,tiktoken.get_encoding('gpt2'),context_window=256,stride=128)\n",
    "\n",
    "print(f'Number of tokens {len(train_ds.token_id)}')\n",
    "print(f'Number of tokens {len(val_ds.token_id)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataLoader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds,batch_size=2,shuffle=False,drop_last=True,num_workers=0)\n",
    "val_dl   = DataLoader(val_ds,batch_size=2,shuffle=False,drop_last=True,num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dl))\n",
    "print(len(val_dl))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "X : torch.Size([2, 256])\n",
      "y : torch.Size([2, 256])\n",
      "------------------------------\n",
      "2\n",
      "X : torch.Size([2, 256])\n",
      "y : torch.Size([2, 256])\n",
      "------------------------------\n",
      "3\n",
      "X : torch.Size([2, 256])\n",
      "y : torch.Size([2, 256])\n",
      "------------------------------\n",
      "4\n",
      "X : torch.Size([2, 256])\n",
      "y : torch.Size([2, 256])\n",
      "------------------------------\n",
      "5\n",
      "X : torch.Size([2, 256])\n",
      "y : torch.Size([2, 256])\n",
      "------------------------------\n",
      "6\n",
      "X : torch.Size([2, 256])\n",
      "y : torch.Size([2, 256])\n",
      "------------------------------\n",
      "7\n",
      "X : torch.Size([2, 256])\n",
      "y : torch.Size([2, 256])\n",
      "------------------------------\n",
      "8\n",
      "X : torch.Size([2, 256])\n",
      "y : torch.Size([2, 256])\n",
      "------------------------------\n",
      "9\n",
      "X : torch.Size([2, 256])\n",
      "y : torch.Size([2, 256])\n",
      "------------------------------\n",
      "10\n",
      "X : torch.Size([2, 256])\n",
      "y : torch.Size([2, 256])\n",
      "------------------------------\n",
      "11\n",
      "X : torch.Size([2, 256])\n",
      "y : torch.Size([2, 256])\n",
      "------------------------------\n",
      "12\n",
      "X : torch.Size([2, 256])\n",
      "y : torch.Size([2, 256])\n",
      "------------------------------\n",
      "13\n",
      "X : torch.Size([2, 256])\n",
      "y : torch.Size([2, 256])\n",
      "------------------------------\n",
      "14\n",
      "X : torch.Size([2, 256])\n",
      "y : torch.Size([2, 256])\n",
      "------------------------------\n",
      "15\n",
      "X : torch.Size([2, 256])\n",
      "y : torch.Size([2, 256])\n",
      "------------------------------\n",
      "16\n",
      "X : torch.Size([2, 256])\n",
      "y : torch.Size([2, 256])\n",
      "------------------------------\n",
      "17\n",
      "X : torch.Size([2, 256])\n",
      "y : torch.Size([2, 256])\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i,(x,y) in enumerate(train_dl):\n",
    "  print(i+1)\n",
    "  print(f'X : {x.shape}')\n",
    "  print(f'y : {y.shape}')\n",
    "  print('---'*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "X : torch.Size([2, 256])\n",
      "y : torch.Size([2, 256])\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i,(x,y) in enumerate(val_dl):\n",
    "  print(i+1)\n",
    "  print(f'X : {x.shape}')\n",
    "  print(f'y : {y.shape}')\n",
    "  print('---'*10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversions \n",
    "\n",
    "These conversion functions allow us to convert text to token_ids,and vice versa easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_token_ids(text,tokenizer=tiktoken.get_encoding('gpt2')):\n",
    "  token_ids = tokenizer.encode(text,allowed_special={'<|endoftext|>'})              # python list.\n",
    "  token_ids_in_tensors = torch.tensor(token_ids).unsqueeze(0)                       # tensor,with batch dimesion.\n",
    "  return token_ids_in_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[15496,   428,   318,   387,  5767,   220, 50256]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_to_token_ids('Hello this is hawar <|endoftext|>')    # Note : the last token_id is 50256, (50257) is the vocab size by the author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_ids_to_text(token_ids_in_tensors,tokenizer=tiktoken.get_encoding('gpt2')):\n",
    "  token_ids = token_ids_in_tensors.squeeze(0).tolist()    # Note: It can only handle batch_size = 1\n",
    "  text = tokenizer.decode(token_ids)\n",
    "  return text "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4 : Transformers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {    #TransformerBlock Level\n",
    "          'd_in':768,\n",
    "           'd_out':768,\n",
    "           'context_window':256,  # You can not have num_tokens greater than this number \n",
    "           'num_heads':12,\n",
    "\n",
    "           'dp_attn':0.1,\n",
    "           'dp_after_attn':0.1,\n",
    "           'dp_after_fc':0.1,\n",
    "\n",
    "           'qkv_bias':False,\n",
    "           \n",
    "            # GPTModel Level\n",
    "           'dp_before_trans':0.1,\n",
    "           'vocab_size':50256+1,\n",
    "           'num_layers':12}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "  def __init__(self,cfg):\n",
    "    super().__init__()\n",
    "\n",
    "    self.norm1 = nn.LayerNorm(cfg['d_out'])\n",
    "\n",
    "    # change #1\n",
    "    self.attn = nn.MultiheadAttention(embed_dim=cfg['d_out'],\n",
    "                                      num_heads=cfg['num_heads'],\n",
    "                                      dropout=cfg['dp_attn'],\n",
    "                                      bias=cfg['qkv_bias'],\n",
    "                                      add_bias_kv=False,\n",
    "                                      batch_first=True\n",
    "                                      )\n",
    "    \n",
    "    \n",
    "    self.dp_after_attn = nn.Dropout(cfg['dp_after_attn'])\n",
    "\n",
    "    self.norm2 = nn.LayerNorm(cfg['d_out'])\n",
    "    self.fc = nn.Sequential(nn.Linear(cfg['d_out'],4*cfg['d_out']),\n",
    "                            nn.GELU(),\n",
    "                            nn.Linear(4*cfg['d_out'],cfg['d_out']))\n",
    "    self.dp_after_fc = nn.Dropout(cfg['dp_after_fc'])\n",
    "\n",
    "  def forward(self,x):\n",
    "    _,num_tokens,_ = x.shape\n",
    "\n",
    "    shortcut = x  \n",
    "    x = self.norm1(x)\n",
    "    x,_ = self.attn(x,x,x,attn_mask= torch.triu(torch.ones(num_tokens,num_tokens),diagonal=1).bool())   # change #2 \n",
    "    x = self.dp_after_attn(x)\n",
    "    x = x + shortcut\n",
    "\n",
    "    shortcut = x    \n",
    "    x = self.norm2(x)\n",
    "    x = self.fc(x)\n",
    "    x = self.dp_after_fc(x)\n",
    "    x = x + shortcut\n",
    "\n",
    "    return x \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 256, 768])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1\n",
    "num_tokens = GPT_CONFIG_124M['context_window']\n",
    "\n",
    "random_data = torch.randn(batch_size,num_tokens,GPT_CONFIG_124M['d_in'])\n",
    "print(random_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0703, -2.8388, -0.0384,  ...,  1.5352, -0.4029, -0.6082],\n",
       "         [-0.2148, -1.1586, -1.3472,  ...,  0.3172,  0.1590,  0.8950],\n",
       "         [-0.4251, -3.1890,  0.1934,  ..., -0.6564,  0.8092, -0.2599],\n",
       "         ...,\n",
       "         [-0.4471,  0.5058, -2.1656,  ...,  0.8858,  0.3880, -0.3287],\n",
       "         [ 0.3484, -1.6628, -1.9328,  ...,  0.0359, -0.7563,  1.4599],\n",
       "         [ 0.8678,  1.4391, -0.2957,  ..., -1.5626,  1.2505, -0.8946]]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans = TransformerBlock(cfg=GPT_CONFIG_124M)\n",
    "trans(random_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 5 : GPT Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTModel(nn.Module):\n",
    "  def __init__(self,cfg):\n",
    "    super().__init__()\n",
    "    self.tok_emb = nn.Embedding(cfg['vocab_size'],cfg['d_in'])\n",
    "    self.pos_emb = nn.Embedding(cfg['context_window'],cfg['d_in'])\n",
    "    self.dp_before_trans = nn.Dropout(cfg['dp_before_trans'])\n",
    "    self.transformer_blocks = nn.Sequential(*[TransformerBlock(cfg) for _ in range(cfg['num_layers'])])\n",
    "    self.final_norm = nn.LayerNorm(cfg['d_out'])\n",
    "    self.head_out = nn.Linear(cfg['d_out'],cfg['vocab_size'])\n",
    "\n",
    "  def forward(self,x):\n",
    "    b,num_tokens = x.shape\n",
    "\n",
    "    tok_em = self.tok_emb(x)\n",
    "    pos_em = self.pos_emb(torch.arange(num_tokens,device=device))   # this is where it can handle dynamic sequence lengths (as long as it's lower than context window)\n",
    "    x = tok_em + pos_em\n",
    "\n",
    "    x = self.dp_before_trans(x)\n",
    "    x = self.transformer_blocks(x)\n",
    "    x = self.final_norm(x)\n",
    "    logits = self.head_out(x)\n",
    "\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPTModel(GPT_CONFIG_124M).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.1011,  0.9919, -0.4107,  ..., -0.2400, -0.8477,  0.6456],\n",
      "         [-0.1797,  0.5026, -0.0126,  ...,  0.3000, -0.1201,  0.8410],\n",
      "         [ 0.1956,  1.3994,  0.3599,  ..., -0.5086,  0.2106, -1.0735],\n",
      "         ...,\n",
      "         [ 1.6026, -0.8599,  0.8412,  ...,  0.0071, -0.6474, -0.2509],\n",
      "         [ 0.5988, -0.3025, -0.3175,  ..., -0.0873, -0.2705, -0.3720],\n",
      "         [-0.2168,  0.2292, -0.1836,  ...,  0.7535,  0.6395, -0.6062]],\n",
      "\n",
      "        [[ 0.0951,  0.5516, -0.2337,  ..., -1.0712, -0.0047,  0.3570],\n",
      "         [ 0.2293,  0.4457, -0.2993,  ..., -0.1531, -0.5117,  1.2723],\n",
      "         [-0.0207, -0.2684, -0.0341,  ..., -0.9701,  0.1178, -1.2332],\n",
      "         ...,\n",
      "         [ 0.1153, -0.0597,  0.4312,  ...,  0.1331, -0.4542, -0.3726],\n",
      "         [ 1.5359,  0.1110, -0.2688,  ...,  0.5526, -0.0789,  0.0379],\n",
      "         [-0.4708, -0.2329, -0.1557,  ...,  0.8003,  0.6335, -0.8232]]])\n",
      "torch.Size([2, 256, 50257])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "  print(model(torch.randint(0,50257,(2,256)).to(device)))        # torch.randint(0,vocab_size,(batch_size,num_tokens))     PS: num_tokens must be <= context_window\n",
    "  print(model(torch.randint(0,50257,(2,256)).to(device)).shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 6 : Next token  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we dont slice the mask, it will throw an error here, why?  beacuase the input num_tokens != context_window \n",
    "\n",
    "def generate_simple_text(starting_text,\n",
    "                         context_window,    # this can be anything between [1,context_window]\n",
    "                         num_tokens_generated = 20,temperature=1,k=None):  \n",
    "  \n",
    "    starting_tokens = text_to_token_ids(starting_text).to(device)       # this will have the shape (B=1,number of tokens after converting text to token ids)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for _ in range(num_tokens_generated):\n",
    "            starting_tokens = starting_tokens[:,-context_window:]    # how far back to pay attention \n",
    "            logits = model(starting_tokens)[:,-1,:]                  # we only want the last vector\n",
    "\n",
    "            # new\n",
    "            if k is not None:\n",
    "              top_logits, _ = torch.topk(logits,k)                                      # find top 3. \n",
    "              new_logits = torch.where(logits<top_logits[:,-1],-torch.inf,logits)       # keep top 3, make other -inf.\n",
    "              probs = torch.softmax(new_logits/temperature,dim=-1)                                  # probability of top 3 , the rest will be zero.\n",
    "              token_predicted = torch.multinomial(probs,num_samples = 1)                # pick one (according to their probability) from top 3.\n",
    "            # End\n",
    "            else : \n",
    "                token_predicted = torch.argmax(logits,dim=-1,keepdim=True)\n",
    "            \n",
    "            starting_tokens = torch.cat([starting_tokens,token_predicted],dim=-1)\n",
    "            \n",
    "        print(token_ids_to_text(starting_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Everty effort moves youmorphAre spawns troubledclipse Qian dwindlingUFC Veniceano delic cis Coconut study supply creditors purposely seismic Ice Scholarship\n"
     ]
    }
   ],
   "source": [
    "generate_simple_text(starting_text='Everty effort moves you',context_window=GPT_CONFIG_124M['context_window'],temperature=0.2,k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 7 : Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(),lr=0.0004,weight_decay =0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss : 8.331      Validation Loss : 6.816\n",
      "Everty effort moves you, and and I I-- and to and, I I was I, and, and, I\n",
      "======================================================================================================================================================\n",
      "Training Loss : 5.784      Validation Loss : 6.208\n",
      "Everty effort moves you to have to see the, I was, I felt it--as I was, I had a\n",
      "======================================================================================================================================================\n",
      "Training Loss : 4.6        Validation Loss : 5.941\n",
      "Everty effort moves you know; but I don't--I was, so. Gis--and I was, and\n",
      "======================================================================================================================================================\n",
      "Training Loss : 3.341      Validation Loss : 5.897\n",
      "Everty effort moves you say, and he said--and I was dead.\" I felt to have been that he was not\n",
      "======================================================================================================================================================\n",
      "Training Loss : 2.357      Validation Loss : 6.053\n",
      "Everty effort moves you know; but I don't think of a little: the tips.\n",
      "\"Yes--she's\n",
      "======================================================================================================================================================\n",
      "Training Loss : 1.618      Validation Loss : 6.322\n",
      "Everty effort moves you know.\n",
      "\"I didn't dabble the fact with a deprecatingly\"Oh,\n",
      "======================================================================================================================================================\n",
      "Training Loss : 1.079      Validation Loss : 6.518\n",
      "Everty effort moves you'd never touched a brush.\"\n",
      "\n",
      "\"I didn't _rose Dubarry_ drawing-room\n",
      "======================================================================================================================================================\n",
      "Training Loss : 0.775      Validation Loss : 6.77\n",
      "Everty effort moves you know; but I don't think of that, so inevitably the background of her own picture--had\n",
      "======================================================================================================================================================\n",
      "Training Loss : 0.629      Validation Loss : 6.897\n",
      "Everty effort moves you'd never touched a wife! But Mrs.\n",
      "\n",
      "\"What a wonder! Made with a dozen\n",
      "======================================================================================================================================================\n",
      "Training Loss : 0.526      Validation Loss : 6.921\n",
      "Everty effort moves you know; but I don't think of that, Mr. She wanted him vindicated--she's\n",
      "======================================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "epochs = 10\n",
    "TRAIN_LOSS,VAL_LOSS = [],[]\n",
    "\n",
    "for epoch in range(epochs) :\n",
    "  train_loss,val_loss = [],[]\n",
    "\n",
    "  # TRAINING \n",
    "  model.train()\n",
    "  for x,y in train_dl:\n",
    "    x,y = x.to(device),y.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    y_hat = model(x)\n",
    "    loss = loss_fn(y_hat.flatten(0,1),y.flatten())    # y_hat result : (512,50257),    y result : (512) \n",
    "    train_loss.append(loss.item())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "  mean_epoch_train_loss = round(torch.mean(torch.tensor(train_loss)).item(),3)\n",
    "  print(f'Training Loss : {mean_epoch_train_loss:<10}',end=' ')\n",
    "  TRAIN_LOSS.append(mean_epoch_train_loss)\n",
    "\n",
    "  # VALIDATION \n",
    "  model.eval()\n",
    "  with torch.no_grad():\n",
    "    for x,y in val_dl:\n",
    "      x,y = x.to(device),y.to(device)\n",
    "      y_hat = model(x)\n",
    "      loss = loss_fn(y_hat.flatten(0,1),y.flatten())\n",
    "      val_loss.append(loss.item())\n",
    "\n",
    "    mean_epoch_val_loss = round(torch.tensor(val_loss).mean().item(),3)\n",
    "    print(f'Validation Loss : {mean_epoch_val_loss}')\n",
    "    VAL_LOSS.append(mean_epoch_val_loss)\n",
    "\n",
    "  # Generate text \n",
    "  generate_simple_text(starting_text='Everty effort moves you',context_window=GPT_CONFIG_124M['context_window'],num_tokens_generated = 20,k=3)\n",
    "\n",
    "  print('======'*25)\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 8 : Plot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "line": {
          "color": "red"
         },
         "mode": "lines",
         "name": "Training Loss",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9
         ],
         "y": [
          8.331,
          5.784,
          4.6,
          3.341,
          2.357,
          1.618,
          1.079,
          0.775,
          0.629,
          0.526
         ]
        },
        {
         "line": {
          "color": "yellow"
         },
         "mode": "lines",
         "name": "Validation Loss",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9
         ],
         "y": [
          6.816,
          6.208,
          5.941,
          5.897,
          6.053,
          6.322,
          6.518,
          6.77,
          6.897,
          6.921
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_curve = go.Scatter(\n",
    "  x = torch.arange(epochs),\n",
    "  y = TRAIN_LOSS,\n",
    "  mode = 'lines',\n",
    "  line = dict(color='red'),\n",
    "  name = 'Training Loss'\n",
    ")\n",
    "\n",
    "valid_curve = go.Scatter(\n",
    "  x = torch.arange(epochs),\n",
    "  y = VAL_LOSS,\n",
    "  mode = 'lines',\n",
    "  line = dict(color='yellow'),\n",
    "  name = 'Validation Loss'\n",
    ")\n",
    "\n",
    "figure = go.Figure(data=[training_curve,valid_curve])\n",
    "figure.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and Saving model weights in Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(\n",
    "  {'model_state_dict':model.state_dict(),\n",
    "   'optimizer_state_dict':optimizer.state_dict()},\n",
    "   'model_and_optimizers.pth'\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qq/xcj55x9n0hs0jx2pcwy46_mc0000gn/T/ipykernel_56823/680644273.py:1: FutureWarning:\n",
      "\n",
      "You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "checkpoint = torch.load('model_and_optimizers.pth',map_location=device)\n",
    "\n",
    "\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(),lr=0.0004,weight_decay =0.1)\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatting",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
