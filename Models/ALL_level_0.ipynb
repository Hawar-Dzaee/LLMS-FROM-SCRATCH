{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch import nn \n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import tiktoken \n",
    "import matplotlib.pyplot as plt \n",
    "import plotly.graph_objects as go \n",
    "\n",
    "import math "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "  device = 'cuda'\n",
    "# elif torch.backends.mps.is_available():\n",
    "#   device = 'mps'\n",
    "else :\n",
    "  device = 'cpu'\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 :  Fetch The Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 20 characters: I HAD always thought\n",
      "Number of Characters: 20479\n"
     ]
    }
   ],
   "source": [
    "with open('the-verdict.txt','r',encoding='utf-8') as f:\n",
    "  raw_text = f.read()\n",
    "\n",
    "print(f'First 20 characters: {raw_text[:20]}')\n",
    "print(f'Number of Characters: {len(raw_text)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 : Dataset Preparation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data(Dataset):\n",
    "  def __init__(self,raw_text,tokenizer,context_window,stride):\n",
    "    self.token_id = tokenizer.encode(raw_text)\n",
    "    self.X = []\n",
    "    self.y = []\n",
    "\n",
    "    for i in range(0,len(self.token_id)-context_window,stride):\n",
    "      input_chunks = self.token_id[i:i+context_window]\n",
    "      output_chunks = self.token_id[(i)+1:(i+context_window) +1]\n",
    "      self.X.append(torch.tensor(input_chunks))\n",
    "      self.y.append(torch.tensor(output_chunks))\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.X)\n",
    "\n",
    "  def __getitem__(self,idx):\n",
    "    return self.X[idx],self.y[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split \n",
    "\n",
    "Notice we split the corpus to train/val before creating the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18431\n"
     ]
    }
   ],
   "source": [
    "ratio = 0.90\n",
    "split_index = int(len(raw_text)* ratio)\n",
    "print(split_index)\n",
    "\n",
    "train_text = raw_text[:split_index]\n",
    "val_text = raw_text[split_index:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens 4612\n",
      "Number of tokens 534\n"
     ]
    }
   ],
   "source": [
    "train_ds = Data(train_text,tiktoken.get_encoding('gpt2'),context_window=256,stride=256)   # notice stride == context_window (in that case there wont be any overlap)\n",
    "val_ds   = Data(val_text,tiktoken.get_encoding('gpt2'),context_window=256,stride=256)     # *Same as above \n",
    "\n",
    "print(f'Number of tokens {len(train_ds.token_id)}')\n",
    "print(f'Number of tokens {len(val_ds.token_id)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataLoader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds,batch_size=2,shuffle=False,drop_last=True, num_workers=0)\n",
    "val_dl   = DataLoader(val_ds,  batch_size=2,shuffle=False,drop_last=False,num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dl))\n",
    "print(len(val_dl))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "X : torch.Size([2, 256])\n",
      "y : torch.Size([2, 256])\n",
      "------------------------------\n",
      "2\n",
      "X : torch.Size([2, 256])\n",
      "y : torch.Size([2, 256])\n",
      "------------------------------\n",
      "3\n",
      "X : torch.Size([2, 256])\n",
      "y : torch.Size([2, 256])\n",
      "------------------------------\n",
      "4\n",
      "X : torch.Size([2, 256])\n",
      "y : torch.Size([2, 256])\n",
      "------------------------------\n",
      "5\n",
      "X : torch.Size([2, 256])\n",
      "y : torch.Size([2, 256])\n",
      "------------------------------\n",
      "6\n",
      "X : torch.Size([2, 256])\n",
      "y : torch.Size([2, 256])\n",
      "------------------------------\n",
      "7\n",
      "X : torch.Size([2, 256])\n",
      "y : torch.Size([2, 256])\n",
      "------------------------------\n",
      "8\n",
      "X : torch.Size([2, 256])\n",
      "y : torch.Size([2, 256])\n",
      "------------------------------\n",
      "9\n",
      "X : torch.Size([2, 256])\n",
      "y : torch.Size([2, 256])\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i,(x,y) in enumerate(train_dl):\n",
    "  print(i+1)\n",
    "  print(f'X : {x.shape}')\n",
    "  print(f'y : {y.shape}')\n",
    "  print('---'*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "X : torch.Size([2, 256])\n",
      "y : torch.Size([2, 256])\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i,(x,y) in enumerate(val_dl):\n",
    "  print(i+1)\n",
    "  print(f'X : {x.shape}')\n",
    "  print(f'y : {y.shape}')\n",
    "  print('---'*10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversions \n",
    "\n",
    "These conversion functions allow us to convert text to token_ids,and vice versa easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_token_ids(text,tokenizer=tiktoken.get_encoding('gpt2')):\n",
    "  token_ids = tokenizer.encode(text,allowed_special={'<|endoftext|>'})              # python list.\n",
    "  token_ids_in_tensors = torch.tensor(token_ids).unsqueeze(0)                       # tensor,with batch dimesion.\n",
    "  return token_ids_in_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[15496,   428,   318,   387,  5767,   220, 50256]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_to_token_ids('Hello this is hawar <|endoftext|>')    # Note : the last token_id is 50256, (50257) is the vocab size by the author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_ids_to_text(token_ids_in_tensors,tokenizer=tiktoken.get_encoding('gpt2')):\n",
    "  token_ids = token_ids_in_tensors.squeeze(0).tolist()    # Note: It can only handle batch_size = 1\n",
    "  text = tokenizer.decode(token_ids)\n",
    "  return text "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3 : Multi-Head-Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "class MultiHeadAttention(nn.Module):\n",
    "  def __init__(self,d_in,d_out,\n",
    "               context_window,    # The context window is needed here to create the mask.\n",
    "               num_heads,\n",
    "               dp_attn,qkv_bias=False):\n",
    "    \n",
    "    super().__init__()\n",
    "\n",
    "    assert d_out%num_heads == 0, 'd_out must be divisble by num_heads'\n",
    "    self.d_out = d_out\n",
    "    self.num_heads = num_heads\n",
    "    self.head_dim = self.d_out //self.num_heads # dimension of each head\n",
    "\n",
    "    self.W_q = nn.Linear(d_in,d_out,bias=qkv_bias)\n",
    "    self.W_k = nn.Linear(d_in,d_out,bias=qkv_bias)\n",
    "    self.W_v = nn.Linear(d_in,d_out,bias=qkv_bias)\n",
    "\n",
    "    self.register_buffer('mask',torch.triu(torch.ones(context_window,context_window),diagonal=1))\n",
    "    # why shape (context_window,context_window) ? beacause we'll use it on Q@KT which will have shape of (b,self.num_heads,context_window,context_window)\n",
    "    # But since we might have different num_tokens(i.e num_tokens is not context_window for every case) we will slice it to [:num_tokens][:num_tokens]\n",
    "    # This slicing wont be necessary if num_tokens == context window\n",
    "    \n",
    "    self.dropout = nn.Dropout(dp_attn)\n",
    "    self.out_proj = nn.Linear(d_out,d_out)\n",
    "\n",
    "\n",
    "  def forward(self,x):\n",
    "    b,num_tokens,d_in = x.shape\n",
    "\n",
    "    Q = self.W_q(x)\n",
    "    K = self.W_k(x)\n",
    "    V = self.W_v(x)\n",
    "\n",
    "    # split \n",
    "    Q = Q.view(b,num_tokens,self.num_heads,self.head_dim).transpose(1,2)  # result : (b,self.num_heads,num_tokens,self.head_dim)\n",
    "    K = K.view(b,num_tokens,self.num_heads,self.head_dim).transpose(1,2)\n",
    "    V = V.view(b,num_tokens,self.num_heads,self.head_dim).transpose(1,2)\n",
    "\n",
    "    # \n",
    "    attn_score = Q @ K.transpose(2,3) # result : (b,self.num_head,num_tokens,num_tokens)\n",
    "    attn_score.masked_fill_(self.mask.bool()[:num_tokens,:num_tokens],-torch.inf)\n",
    "    attn_weight = torch.softmax(attn_score/(K.shape[-1]**0.5),dim=-1)\n",
    "    attn_weight = self.dropout(attn_weight)\n",
    "\n",
    "    context_vec = attn_weight @ V # result : (b,self.num_head,num_toknes,self.head_dim)\n",
    "    context_vec = context_vec.transpose(1,2).contiguous().view(b,num_tokens,self.d_out)\n",
    "    context_vec = self.out_proj(context_vec)\n",
    "\n",
    "    return context_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4 : Transformers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "  def __init__(self,cfg):\n",
    "    super().__init__()\n",
    "\n",
    "    self.norm1 = nn.LayerNorm(cfg['d_out'])\n",
    "    self.attn = MultiHeadAttention(cfg['d_in'],cfg['d_out'],cfg['context_window'],cfg['num_heads'],cfg['dp_attn'],cfg['qkv_bias'])\n",
    "    self.dp_after_attn = nn.Dropout(cfg['dp_after_attn'])\n",
    "\n",
    "    self.norm2 = nn.LayerNorm(cfg['d_out'])\n",
    "    self.fc = nn.Sequential(nn.Linear(cfg['d_out'],4*cfg['d_out']),\n",
    "                            nn.GELU(),\n",
    "                            nn.Linear(4*cfg['d_out'],cfg['d_out']))\n",
    "    self.dp_after_fc = nn.Dropout(cfg['dp_after_fc'])\n",
    "\n",
    "  def forward(self,x):\n",
    "    shortcut = x  \n",
    "    x = self.norm1(x)\n",
    "    x = self.attn(x)\n",
    "    x = self.dp_after_attn(x)\n",
    "    x = x + shortcut\n",
    "\n",
    "    shortcut = x\n",
    "    x = self.norm2(x)\n",
    "    x = self.fc(x)\n",
    "    x = self.dp_after_fc(x)\n",
    "    x = x + shortcut\n",
    "\n",
    "    return x \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model's Configuration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {    #TransformerBlock Level\n",
    "          'd_in':768,\n",
    "           'd_out':768,\n",
    "           'context_window':256,  # You can not have num_tokens greater than this number \n",
    "           'num_heads':12,\n",
    "           \n",
    "           'dp_attn':0.1,\n",
    "           'dp_after_attn':0.1,\n",
    "           'dp_after_fc':0.1,\n",
    "\n",
    "           'qkv_bias':False,\n",
    "           \n",
    "            # GPTModel Level\n",
    "           'dp_before_attn':0.1,\n",
    "           'vocab_size':50256+1,\n",
    "           'num_layers':12}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 5 : GPT Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTModel(nn.Module):\n",
    "  def __init__(self,cfg):\n",
    "    super().__init__()\n",
    "    self.tok_emb = nn.Embedding(cfg['vocab_size'],cfg['d_in'])\n",
    "    self.pos_emb = nn.Embedding(cfg['context_window'],cfg['d_in'])\n",
    "    self.dp_before_trans = nn.Dropout(cfg['dp_before_attn'])\n",
    "    self.transformer_blocks = nn.Sequential(*[TransformerBlock(cfg) for _ in range(cfg['num_layers'])])\n",
    "    self.final_norm = nn.LayerNorm(cfg['d_out'])\n",
    "    self.head_out = nn.Linear(cfg['d_out'],cfg['vocab_size'])\n",
    "\n",
    "  def forward(self,x):\n",
    "    b,num_tokens = x.shape\n",
    "\n",
    "    tok_em = self.tok_emb(x)\n",
    "    pos_em = self.pos_emb(torch.arange(num_tokens,device=device))   # this is where it can handle dynamic sequence lengths (as long as it's lower than context window)\n",
    "    x = tok_em + pos_em\n",
    "\n",
    "    x = self.dp_before_trans(x)\n",
    "    x = self.transformer_blocks(x)\n",
    "    x = self.final_norm(x)\n",
    "    logits = self.head_out(x)\n",
    "\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPTModel(GPT_CONFIG_124M).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-1.1501e-01, -4.0099e-01, -7.0368e-02,  ...,  5.5857e-02,\n",
      "          -4.8014e-01,  3.7116e-01],\n",
      "         [ 6.1407e-02, -1.4992e-01,  1.0680e+00,  ...,  4.3743e-01,\n",
      "          -7.0324e-01,  4.2321e-01],\n",
      "         [ 4.6695e-01,  2.3328e-01, -3.4185e-02,  ...,  6.2094e-01,\n",
      "          -6.9301e-01,  3.5567e-01],\n",
      "         ...,\n",
      "         [ 8.3024e-02, -2.7019e-01,  5.7516e-02,  ...,  4.7997e-01,\n",
      "           5.8081e-02,  6.7800e-01],\n",
      "         [ 5.8204e-01,  6.1453e-01,  6.5674e-01,  ..., -2.5922e-01,\n",
      "          -1.9805e-01,  5.0750e-01],\n",
      "         [-3.4647e-01,  6.2501e-01,  6.0778e-01,  ...,  5.1414e-01,\n",
      "           3.9566e-01, -8.4009e-01]],\n",
      "\n",
      "        [[-5.2159e-01, -3.2698e-01, -3.3057e-01,  ...,  1.9990e-01,\n",
      "           6.9118e-01,  3.8865e-01],\n",
      "         [ 2.7139e-01, -8.9852e-02,  3.9952e-01,  ...,  5.9899e-01,\n",
      "          -3.8721e-01, -4.0687e-01],\n",
      "         [ 5.2349e-01, -7.6593e-02, -6.5530e-01,  ..., -3.0248e-01,\n",
      "          -1.1583e+00, -5.8816e-01],\n",
      "         ...,\n",
      "         [ 2.2410e-01, -1.3619e-01, -1.0972e+00,  ..., -5.8028e-01,\n",
      "           1.2618e+00,  4.0446e-01],\n",
      "         [ 6.1640e-01,  2.0796e+00,  8.5094e-01,  ...,  9.0663e-02,\n",
      "           2.7238e-01,  9.6674e-01],\n",
      "         [-1.3609e-01,  8.1424e-01, -1.3464e-03,  ...,  2.5297e-01,\n",
      "           5.9572e-01, -9.1828e-01]]])\n",
      "torch.Size([2, 256, 50257])\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "  print(model(torch.randint(0,50257,(2,256)).to(device)))        # torch.randint(0,vocab_size,(batch_size,num_tokens))     PS: num_tokens must be <= context_window\n",
    "  print(model(torch.randint(0,50257,(2,256)).to(device)).shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 6 : Next token  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we dont slice the mask, it will throw an error here, why?  beacuase the input num_tokens != context_window \n",
    "\n",
    "def generate_simple_text(starting_text,\n",
    "                         context_window,    # this can be anything between [1,context_window]\n",
    "                         num_tokens_generated = 20,temperature=1,k=None):  \n",
    "  \n",
    "    starting_tokens = text_to_token_ids(starting_text).to(device)       # this will have the shape (B=1,number of tokens after converting text to token ids)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for _ in range(num_tokens_generated):\n",
    "            starting_tokens = starting_tokens[:,-context_window:]    # how far back to pay attention \n",
    "            logits = model(starting_tokens)[:,-1,:]                  # we only want the last vector\n",
    "\n",
    "            # new\n",
    "            if k is not None:\n",
    "              top_logits, _ = torch.topk(logits,k)                                      # find top 3. \n",
    "              new_logits = torch.where(logits<top_logits[:,-1],-torch.inf,logits)       # keep top 3, make other -inf.\n",
    "              probs = torch.softmax(new_logits/temperature,dim=-1)                                  # probability of top 3 , the rest will be zero.\n",
    "              token_predicted = torch.multinomial(probs,num_samples = 1)                # pick one (according to their probability) from top 3.\n",
    "            # End\n",
    "            else : \n",
    "                token_predicted = torch.argmax(logits,dim=-1,keepdim=True)\n",
    "            \n",
    "            starting_tokens = torch.cat([starting_tokens,token_predicted],dim=-1)\n",
    "            \n",
    "        print(token_ids_to_text(starting_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Everty effort moves youreligiouszzo distortionscommerceventionalplings intellectual lore Mud }}annah Specialiologist Examplesector461 Exhibitvention Yugoslav aggrav\n"
     ]
    }
   ],
   "source": [
    "generate_simple_text(starting_text='Everty effort moves you',context_window=GPT_CONFIG_124M['context_window'],temperature=0.2,k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 7 : Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(),weight_decay =0.1)   # weight decay is L2 norm regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 00   Training Loss : 8.533      Validation Loss : 6.898\n",
      "Everty effort moves you he,, he I, he I, he I I, he I he was I I I\n",
      "=============================================================================================================================\n",
      "Epoch : 01   Training Loss : 6.982      Validation Loss : 6.703\n",
      "Everty effort moves you a---- to to to to.\n",
      "\n",
      "\n",
      "\n",
      "\" to---- to.\n",
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "Epoch : 02   Training Loss : 5.959      Validation Loss : 6.734\n",
      "Everty effort moves you\n",
      "\" heburn of the\n",
      "\n",
      "\"\n",
      "\n",
      "\n",
      "\n",
      "\".\n",
      "\n",
      "\n",
      "\n",
      "\"\n",
      "=============================================================================================================================\n",
      "Epoch : 03   Training Loss : 5.728      Validation Loss : 6.72\n",
      "Everty effort moves you\n",
      "\n",
      "He to the\n",
      "I to, and of the, I of of the.\n",
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "Epoch : 04   Training Loss : 5.445      Validation Loss : 6.544\n",
      "Everty effort moves youburnburn-- the house, as aisburn-- the factburn-- and I was the .\n",
      "=============================================================================================================================\n",
      "Epoch : 05   Training Loss : 5.021      Validation Loss : 6.474\n",
      "Everty effort moves you he was a a the \" was a Jack's the picture the picture the picture the picture me to\n",
      "=============================================================================================================================\n",
      "Epoch : 06   Training Loss : 4.665      Validation Loss : 6.416\n",
      "Everty effort moves you to me to see and, I had been the donkey with a--his--and of his own\n",
      "=============================================================================================================================\n",
      "Epoch : 07   Training Loss : 3.948      Validation Loss : 6.388\n",
      "Everty effort moves you know, I had been a little to face a a little me--the. I was not,\n",
      "=============================================================================================================================\n",
      "Epoch : 08   Training Loss : 3.168      Validation Loss : 6.546\n",
      "Everty effort moves you know to go a little, and I can, and I felt up.\n",
      "\"--and was\n",
      "=============================================================================================================================\n",
      "Epoch : 09   Training Loss : 2.396      Validation Loss : 6.694\n",
      "Everty effort moves you Hermia's tears I felt--I turned, I had the Sev--the Mrs.\n",
      "\"\n",
      "=============================================================================================================================\n",
      "Epoch : 10   Training Loss : 1.644      Validation Loss : 6.856\n",
      "Everty effort moves you that mighty up his pictures? My his cheeks his history a little enough--so it was no great\n",
      "=============================================================================================================================\n",
      "Epoch : 11   Training Loss : 0.996      Validation Loss : 7.112\n",
      "Everty effort moves you through, and in the axioms with an down with equanimity. Gisburn's\n",
      "=============================================================================================================================\n",
      "Epoch : 12   Training Loss : 0.622      Validation Loss : 7.273\n",
      "Everty effort moves you began to go a brush.\"\n",
      "\n",
      "\n",
      "I told told me--had not existed till nearly a\n",
      "=============================================================================================================================\n",
      "Epoch : 13   Training Loss : 0.419      Validation Loss : 7.475\n",
      "Everty effort moves you'd never touched a little wild--I felt nervous and uncertain.\n",
      "\n",
      "\n",
      "He my work,\n",
      "=============================================================================================================================\n",
      "Epoch : 14   Training Loss : 0.331      Validation Loss : 7.648\n",
      "Everty effort moves you know\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\"Oh,\n",
      "=============================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "epochs = 10 \n",
    "TRAIN_LOSS,VAL_LOSS = [],[]\n",
    "\n",
    "for epoch in range(epochs) :\n",
    "  print(f'Epoch : {epoch:02d}',end='   ')                                                    # first print()\n",
    "  train_loss,val_loss = [],[]\n",
    "\n",
    "  # TRAINING \n",
    "  model.train()\n",
    "  for x,y in train_dl:\n",
    "    x,y = x.to(device),y.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    y_hat = model(x)\n",
    "    loss = loss_fn(y_hat.flatten(0,1),y.flatten())    # y_hat result : (512,50257),    y result : (512) \n",
    "    train_loss.append(loss.item())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "  mean_epoch_train_loss = round(torch.mean(torch.tensor(train_loss)).item(),3)\n",
    "  print(f'Training Loss : {mean_epoch_train_loss:<10}',end=' ')                                 # second print()         \n",
    "  TRAIN_LOSS.append(mean_epoch_train_loss)\n",
    "\n",
    "  # VALIDATION \n",
    "  model.eval()\n",
    "  with torch.no_grad():\n",
    "    for x,y in val_dl:\n",
    "      x,y = x.to(device),y.to(device)\n",
    "      y_hat = model(x)\n",
    "      loss = loss_fn(y_hat.flatten(0,1),y.flatten())\n",
    "      val_loss.append(loss.item())\n",
    "\n",
    "    mean_epoch_val_loss = round(torch.tensor(val_loss).mean().item(),3)                         # Third print()\n",
    "    print(f'Validation Loss : {mean_epoch_val_loss}')\n",
    "    VAL_LOSS.append(mean_epoch_val_loss)\n",
    "\n",
    "  # Generate text \n",
    "  generate_simple_text(starting_text='Everty effort moves you',context_window=GPT_CONFIG_124M['context_window'],num_tokens_generated = 20,k=3)\n",
    "\n",
    "  print('====='*25)\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 8.0 : Train/Val Loss Plot  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "line": {
          "color": "red"
         },
         "mode": "lines",
         "name": "Training Loss",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14
         ],
         "y": [
          8.533,
          6.982,
          5.959,
          5.728,
          5.445,
          5.021,
          4.665,
          3.948,
          3.168,
          2.396,
          1.644,
          0.996,
          0.622,
          0.419,
          0.331
         ]
        },
        {
         "line": {
          "color": "yellow"
         },
         "mode": "lines",
         "name": "Validation Loss",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14
         ],
         "y": [
          6.898,
          6.703,
          6.734,
          6.72,
          6.544,
          6.474,
          6.416,
          6.388,
          6.546,
          6.694,
          6.856,
          7.112,
          7.273,
          7.475,
          7.648
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_curve = go.Scatter(\n",
    "  x = torch.arange(n_epochs),\n",
    "  y = TRAIN_LOSS,\n",
    "  mode = 'lines',\n",
    "  line = dict(color='red'),\n",
    "  name = 'Training Loss'\n",
    ")\n",
    "\n",
    "valid_curve = go.Scatter(\n",
    "  x = torch.arange(n_epochs),\n",
    "  y = VAL_LOSS,\n",
    "  mode = 'lines',\n",
    "  line = dict(color='yellow'),\n",
    "  name = 'Validation Loss'\n",
    ")\n",
    "\n",
    "figure = go.Figure(data=[training_curve,valid_curve])\n",
    "figure.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and Saving model weights in Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(\n",
    "  {'model_state_dict':model.state_dict(),\n",
    "   'optimizer_state_dict':optimizer.state_dict()},\n",
    "   'model_and_optimizers.pth'\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qq/xcj55x9n0hs0jx2pcwy46_mc0000gn/T/ipykernel_74572/680644273.py:1: FutureWarning:\n",
      "\n",
      "You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "checkpoint = torch.load('model_and_optimizers.pth',map_location=device)\n",
    "\n",
    "\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(),lr=0.0004,weight_decay =0.1)\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatting",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
